{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last updated 27 February 2021\n",
    "\n",
    "An `ipywidgets`-based Algonquian-English/English-Algonquian translation gui.\n",
    "\n",
    "To run in a browser window, use the following command in the command line:\n",
    "\n",
    "> `voila gui.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import ipywidgets as widgets\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather all the entries from entries.csv\n",
    "\n",
    "class Entry():\n",
    "    def __init__(self, alg, eng, gloss, analysis, verb_type=None):\n",
    "        self.alg = alg\n",
    "        self.eng = eng\n",
    "        self.gloss = gloss\n",
    "        self.analysis = analysis\n",
    "        self.verb_type = verb_type\n",
    "        \n",
    "        self.eng_lower = self.eng.lower()\n",
    "    \n",
    "entries_df = pandas.read_csv('entries.csv',header=1)\n",
    "entries = []\n",
    "for row in entries_df.itertuples():\n",
    "    alg = row.Algonquian\n",
    "    eng = row.English\n",
    "    gloss = row.Gloss\n",
    "    analysis = row.Analysis\n",
    "    new_entry = Entry(alg,eng,gloss,analysis)\n",
    "    entries.append(new_entry)\n",
    "\n",
    "eng_entries = [entry.eng_lower for entry in entries]\n",
    "alg_entries = [entry.alg for entry in entries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather all verb stems from glossary.csv\n",
    "\n",
    "def insert_some(text,end):\n",
    "    text = re.sub('__',' some'+end+' ',text)\n",
    "    text = re.sub('_',' ',text)\n",
    "    return text\n",
    "\n",
    "class Stem():\n",
    "    def __init__(self,eng,TA=None,TI=None,AI=None,II=None):\n",
    "        self.eng = eng\n",
    "        self.TA = TA if TA != '-' else None\n",
    "        self.TI = TI if TI != '-' else None\n",
    "        self.AI = AI if AI != '-' else None\n",
    "        self.II = II if II != '-' else None\n",
    "        self.alg = list(set([self.TA,self.TI,self.AI,self.II]))\n",
    "        self.alg.remove(None)\n",
    "        \n",
    "        self.eng_w_just_space = re.sub('_+',' ',self.eng)\n",
    "        \n",
    "        eng_w_someone = insert_some(eng,'one')\n",
    "        eng_w_something = insert_some(eng,'thing')\n",
    "        \n",
    "        self.eng_w_some = eng_w_someone if self.TA else eng_w_something\n",
    "        self.eng_w_spaces = list(set([self.eng_w_just_space,self.eng_w_some]))\n",
    "        \n",
    "glossary_df = pandas.read_csv('glossary.csv')\n",
    "\n",
    "stems = []\n",
    "for row in glossary_df.itertuples():\n",
    "    eng = row.eng_updated_210129\n",
    "    TA = row.TA if row.TA != '-' else None\n",
    "    TI = row.TI if row.TI != '-' else None\n",
    "    AI = row.AI if row.AI != '-' else None\n",
    "    II = row.II if row.II != '-' else None\n",
    "    new_stem = Stem(eng,TA,TI,AI,II)\n",
    "    stems.append(new_stem)\n",
    "    \n",
    "eng_stems_w_spaces = [stem.eng_w_spaces for stem in stems]\n",
    "eng_stems_w_spaces = [item for sublist in eng_stems_w_spaces for item in sublist]\n",
    "\n",
    "alg_stems = [stem.alg for stem in stems if \"/\" not in stem.alg]\n",
    "alg_stems = list(set([item for sublist in alg_stems for item in sublist]))\n",
    "alg_stems.extend(['mir','mis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to clean up and classify the input\n",
    "punctuation = \"\\\"'.,!?\"\n",
    "\n",
    "def clean_input(text):\n",
    "    text = text.strip().lower()\n",
    "    text = ''.join([c for c in text if c not in punctuation])\n",
    "    text = re.sub('dont',\"do not\", text)\n",
    "    text = re.sub('you guys','yall',text)\n",
    "    text = re.sub(' the ',' that ',text)\n",
    "    text = re.sub(r'\\s\\s+',' ',text)\n",
    "    \n",
    "    input_type = ('none','none')\n",
    "    \n",
    "    fixed_text = re.sub('^to ','',text)\n",
    "    fixed_text = re.sub('^(is|am|are) ','be ',text)\n",
    "        \n",
    "    if 'be '+text in eng_stems_w_spaces:\n",
    "        fixed_text = 'be '+text\n",
    "    if text == 'has':\n",
    "        fixed_text = 'have'\n",
    "        \n",
    "    if text in alg_entries:\n",
    "        input_type = ('conjugated', 'Algonquian')\n",
    "        \n",
    "    elif text in alg_stems:\n",
    "        input_type = ('stem', 'Algonquian')\n",
    "        \n",
    "    elif text in eng_entries:        \n",
    "        input_type = ('conjugated','English')\n",
    "        \n",
    "    elif text in eng_stems_w_spaces or fixed_text in eng_stems_w_spaces:\n",
    "        input_type = ('stem', 'English')\n",
    "        \n",
    "    else:\n",
    "        input_type = ('invalid','invalid')\n",
    "        \n",
    "    return text, input_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_format_map = {entry.eng_lower:entry.eng for entry in entries}\n",
    "\n",
    "eng_words = []\n",
    "for sentence in eng_entries:\n",
    "    new_words = sentence.split()\n",
    "    eng_words.extend([w for w in new_words if w not in eng_words])\n",
    "\n",
    "valid_words = eng_words + alg_entries + ['will']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_invalid_sentence(text):\n",
    "    if 'will' in text:\n",
    "                    return 'You may be trying to translate a future-tense sentence. Currently, the dictionary only ' + \\\n",
    "                           'supports present tense.\\nBut you can easily get the future tense by putting the word \"mus\"' + \\\n",
    "                           'in front of the present tense! For example:\\n' + \\\n",
    "                           '\\t\"I see you.\"\\t\\t==> \"kunáwush\"\\n' + \\\n",
    "                           '\\t\"I will see you.\"\\t==> \"mus kunáwush\"'\n",
    "    \n",
    "    for word in text.split(' '):\n",
    "        if word not in valid_words or word in ['something']:\n",
    "\n",
    "            not_allowed = ['it','thing','something']\n",
    "            for w in not_allowed:\n",
    "                if ' '+w in text or re.compile('^'+w).match(text):\n",
    "                    return 'It looks like you used the word \"'+w+'.\" Try replacing this word with one of the following:\\n' +\\\n",
    "                            '\\n\\t'.join(['\\tthat NA','those NAs','that NI','those NIs',\n",
    "                                       'a NA','some NAs','a NI','some NIs'])\n",
    "\n",
    "            pronouns = ['she','they','him','her','them','he']\n",
    "            for p in pronouns:\n",
    "                if word == p:\n",
    "                    return 'It looks like you used the word \"'+p+'.\" Try replacing this word with one of the following:\\n' +\\\n",
    "                            '\\n\\t'.join(['\\tthat NA','those NAs','a NA','some NAs'])                \n",
    "\n",
    "            message = \"The word \\\"\"+word+'\" is not recongized.\\n'\n",
    "            if 'a' in word or 'o' in word:\n",
    "                message += \"Try double checking the spelling of special characters (á, ô)!\"\n",
    "\n",
    "            return message\n",
    "    return \"This phrase was not found in the dictionary.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text):\n",
    "    warning = None\n",
    "    found = True\n",
    "    \n",
    "    text = clean_input(text)[0]\n",
    "    text = re.sub(\"y'all\",\"yall\",text)\n",
    "    \n",
    "    language = clean_input(text)[1][1]\n",
    "    text_type = clean_input(text)[1][0]\n",
    "   \n",
    "    if text_type == 'stem':\n",
    "        return \"This looks like a lone verb stem.\\nTry using the Search function instead.\"\n",
    "    \n",
    "    elif text_type == 'conjugated':\n",
    "    \n",
    "        if language == 'Algonquian':\n",
    "            trans_analys = [(entry.eng,entry.analysis) for entry in entries if entry.alg == text]\n",
    "\n",
    "        elif language == 'English':\n",
    "            trans_analys = [(entry.alg,entry.analysis) for entry in entries if entry.eng_lower == text]\n",
    "\n",
    "            r_we = re.compile('^we(?!-)|\\swe(?!-)')\n",
    "            r_youyall = re.compile('.*you.*|.*yall.*')\n",
    "            if r_we.match(text) and not r_youyall.match(text):\n",
    "                warning = 'Heads up! It looks like you\\'ve used the word \"we.\" If you mean \"we'+ \\\n",
    "                            ' (including the person I\\'m talking to)\", then try using \"we-inc\" instead.\\n\\n'\n",
    "\n",
    "            r_us = re.compile('.*us(?!-)$|.*\\sus(?!-)\\s')\n",
    "            if r_us.match(text) and not r_youyall.match(text):\n",
    "                warning = 'Heads up! It looks like you\\'ve used the word \"us.\" If you mean \"us'+ \\\n",
    "                            ' (including the person I\\'m talking to)\", then try using \"us-inc\" instead.\\n\\n'\n",
    "\n",
    "            text = eng_format_map[text]+'.'\n",
    "            \n",
    "        def output(trans,analys):\n",
    "            return '\\nTranslation:\\t'+trans + \\\n",
    "                   '\\nBreak it down:\\t'+analys\n",
    "\n",
    "        num_translations = len(trans_analys)\n",
    "\n",
    "        message = language+':\\t'+text + \\\n",
    "                 '\\n\\n{} translation(s) of \"{}\" were found:\\n'.format(num_translations,text) + \\\n",
    "                 '\\n'.join([output(tr,an) for tr,an in trans_analys])\n",
    "\n",
    "        if warning:\n",
    "            message = warning + output\n",
    "\n",
    "        return message\n",
    "        \n",
    "    else:\n",
    "        return handle_invalid_sentence(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_button_clicked(b):\n",
    "    response = translate(w_text.value)\n",
    "    w_output.clear_output()\n",
    "    with w_output:\n",
    "        print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_forms(text):\n",
    "    num_forms = 0\n",
    "    text = clean_input(text)[0]\n",
    "    \n",
    "    language = clean_input(text)[1][1]\n",
    "    \n",
    "    if clean_input(text)[1][0] == 'conjugated':\n",
    "        return \"This looks like a conjugated form. Try searching for just the verb stem.\\nOr, try \" + \\\n",
    "               \"using the Translate function instead.\"\n",
    "    \n",
    "    text = re.sub('^to ','',text)\n",
    "    text = re.sub('^(is|am|are) ','be ',text)\n",
    "    \n",
    "    if 'be '+text in eng_stems_w_spaces:\n",
    "        text = 'be '+text\n",
    "    if text == 'has':\n",
    "        text = 'have'\n",
    "        \n",
    "    if text not in eng_stems_w_spaces and text not in alg_stems:\n",
    "        return '\"' + text + '\" was not found in the dictionary.'\n",
    "        \n",
    "    if text in eng_stems_w_spaces:\n",
    "        eng = [stem.eng for stem in stems if text in stem.eng_w_spaces][0]\n",
    "        r_eng = re.compile(eng)\n",
    "        forms_transl = [(entry.eng,entry.alg) for entry in entries if r_eng.match(entry.gloss)]\n",
    "        \n",
    "    elif text in alg_stems:\n",
    "        r_analys = re.compile('^(ku|nu|wu)+\\+'+text)\n",
    "        forms_transl = [(entry.alg,entry.eng) for entry in entries if r_analys.match(entry.analysis)]\n",
    "    \n",
    "    num_forms = len(forms_transl)\n",
    "    \n",
    "    message = '\"{}\" is a(n) {} verb stem.\\n'.format(text,language) + \\\n",
    "              '{} forms of \"{}\" were found\\n\\n'.format(num_forms,text) + \\\n",
    "              '\\n'.join([f+'\\t\\t'+t for f,t in forms_transl])\n",
    "    \n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_button_clicked2(b):\n",
    "    response = get_all_forms(w_text2.value)\n",
    "    w_output2.clear_output()\n",
    "    with w_output2:\n",
    "        print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_same_pattern(text):\n",
    "    \n",
    "    text = clean_input(text)[0]\n",
    "    language = clean_input(text)[1][1]\n",
    "    text_type = clean_input(text)[1][0]\n",
    "    \n",
    "    if text_type == 'stem':\n",
    "        return 'It looks like this is a verb stem.\\n' + \\\n",
    "               'Try searching for a conjugated Algonquian verb or a full English sentence.'\n",
    "    \n",
    "    elif text_type == 'conjugated':\n",
    "        if language == 'Algonquian' and text_type == 'conjugated':\n",
    "            glosses = [re.sub('^([a-z]|_)+(?!12ID)','',entry.gloss) for entry in entries if entry.alg == text]\n",
    "            results = []\n",
    "            for gloss in glosses:\n",
    "                new_results = [(entry.alg,entry.analysis,entry.eng+'.') for entry in entries if\n",
    "                           re.sub('^([a-z]|_)+(?!12ID)','',entry.gloss)==gloss]\n",
    "                results.append(new_results)\n",
    "\n",
    "            title = 'Algonquian\\t\\tAnalysis\\t\\tEnglish\\n'+\\\n",
    "                    '----------\\t\\t--------\\t\\t-------\\n'\n",
    "\n",
    "        elif language == 'English' and text_type == 'conjugated':\n",
    "            gloss = [re.sub('^([a-z]|_)+(?!12ID)','',entry.gloss) for entry in entries if entry.eng_lower == text][0]\n",
    "            results = [[(entry.eng+'.',entry.alg,entry.analysis) for entry in entries if\n",
    "                       re.sub('^([a-z]|_)+(?!12ID)','',entry.gloss)==gloss]]\n",
    "\n",
    "            title = 'English\\t\\t\\tAlgonquian\\t\\tAnalysis\\n'+\\\n",
    "                    '-------\\t\\t\\t----------\\t\\t--------\\n'\n",
    "\n",
    "        output = '\\n\\n'.join(['\\n'.join([al+'\\t\\t'+an+'\\t\\t'+en for al,an,en in result]) for result in results])\n",
    "        \n",
    "        message = title + output\n",
    "        return message\n",
    "    \n",
    "    else:\n",
    "        return handle_invalid_sentence(text)\n",
    "    \n",
    "        \n",
    "def on_button_clicked3(b):\n",
    "    response = find_same_pattern(w_text3.value)\n",
    "    w_output3.clear_output()\n",
    "    with w_output3:\n",
    "        print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c2c4e6ea8e48f29a75b7d8fe6cd628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h1><b>Algonquian Dictionary</b></h>'), HTML(value='<h2><b>Translate</b></h>'), Tex…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w_mainheader = widgets.HTML('<h1><b>Algonquian Dictionary</b></h>')\n",
    "        \n",
    "w_header = widgets.HTML('<h2><b>Translate</b></h>')\n",
    "w_text = widgets.Textarea(placeholder='Write something (English or Algonquian)!', layout=widgets.Layout(width ='40%'))\n",
    "w_button = widgets.Button(description='Translate')\n",
    "w_button.on_click(on_button_clicked)\n",
    "w_output = widgets.Output()\n",
    "\n",
    "w_header2 = widgets.HTML('<h2><b><br>See all forms of a verb</b></h>')\n",
    "w_text2 = widgets.Textarea(placeholder='Search for an English verb or an Algonquian verb stem',\n",
    "                              layout=widgets.Layout(width='40%'))\n",
    "w_button2 = widgets.Button(description='Search')\n",
    "w_button2.on_click(on_button_clicked2)\n",
    "w_output2 = widgets.Output()\n",
    "\n",
    "w_header3 = widgets.HTML('<h2><b><br>Find words with the same pattern</b></h>')\n",
    "w_text3 = widgets.Textarea(placeholder='Search for a conjugated Algonquian verb or English sentence', layout=widgets.Layout(width='40%'))\n",
    "w_button3 = widgets.Button(description='Search')\n",
    "w_button3.on_click(on_button_clicked3)\n",
    "w_output3 = widgets.Output()\n",
    "\n",
    "ui_items = [w_mainheader,w_header,w_text,w_button, w_output,\n",
    "            w_header2,w_text2,w_button2,w_output2,\n",
    "            w_header3,w_text3,w_button3,w_output3]\n",
    "w_ui = widgets.VBox(ui_items, layout=widgets.Layout(align_items='center'))\n",
    "display(w_ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
